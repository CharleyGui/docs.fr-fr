---
title: Métriques ML.NET
description: Découvrir les métriques qui sont utilisées pour évaluer les performances d’un modèle ML.NET
ms.date: 12/17/2019
ms.openlocfilehash: 4aca8dbdd9f137509ab9167ecc77f9ca6994e415
ms.sourcegitcommit: aa6d8a90a4f5d8fe0f6e967980b8c98433f05a44
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 09/16/2020
ms.locfileid: "90679506"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="3d6f7-103">Évaluer votre modèle ML.NET à l’aide de mesures</span><span class="sxs-lookup"><span data-stu-id="3d6f7-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="3d6f7-104">Comprenez les mesures utilisées pour évaluer un modèle ML.NET.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="3d6f7-105">Les mesures d’évaluation sont spécifiques au type de Machine Learning tâche qu’un modèle effectue.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="3d6f7-106">Par exemple, pour la tâche de classification, le modèle est évalué en mesurant le degré de correspondance d’une catégorie prédite avec la catégorie réelle.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="3d6f7-107">Pour le clustering, l’évaluation est basée sur la façon dont les éléments en cluster sont fermés et sur la quantité de séparation entre les clusters.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="3d6f7-108">Métriques d’évaluation pour la classification binaire</span><span class="sxs-lookup"><span data-stu-id="3d6f7-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="3d6f7-109">Mesures</span><span class="sxs-lookup"><span data-stu-id="3d6f7-109">Metrics</span></span>   |      <span data-ttu-id="3d6f7-110">Description</span><span class="sxs-lookup"><span data-stu-id="3d6f7-110">Description</span></span>      |  <span data-ttu-id="3d6f7-111">Recherche</span><span class="sxs-lookup"><span data-stu-id="3d6f7-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="3d6f7-112">**Précision**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-112">**Accuracy**</span></span> |  <span data-ttu-id="3d6f7-113">La [précision](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) est la proportion de prédictions correctes avec un jeu de données de test.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="3d6f7-114">Elle représente le rapport entre le nombre de prédictions correctes et le nombre total d’échantillons d’entrée.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="3d6f7-115">Il fonctionne bien s’il existe un nombre similaire d’exemples appartenant à chaque classe.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="3d6f7-116">**Plus la précision est proche de 1,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="3d6f7-117">Toutefois, la valeur exacte 1,00 indique un problème (en règle générale, une fuite d’étiquette/cible, un surapprentissage ou un test avec des données d’entraînement).</span><span class="sxs-lookup"><span data-stu-id="3d6f7-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="3d6f7-118">Lorsque les données de test sont déséquilibrées (lorsque la plupart des instances appartiennent à l’une des classes), le jeu de données est petit, ou les scores sont 0,00 ou 1,00, la précision ne capture pas vraiment l’efficacité d’un classifieur et vous devez vérifier des métriques supplémentaires.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn't really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="3d6f7-119">**AUC**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-119">**AUC**</span></span> |    <span data-ttu-id="3d6f7-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) ou *Area sous la courbe* mesure la zone sous la courbe créée en balayant le taux réel positif par rapport au taux de faux positifs.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="3d6f7-121">**Plus la précision est proche de 1,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="3d6f7-122">Elle doit être supérieure à 0,50 pour qu’un modèle soit acceptable.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="3d6f7-123">Un modèle avec AUC de 0,50 ou moins est inutile.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="3d6f7-124">**Zone sous une courbe de précision/rappel**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-124">**AUCPR**</span></span> | <span data-ttu-id="3d6f7-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) ou *zone sous la courbe d’une courbe de rappel de précision*: mesure utile du succès de la prédiction lorsque les classes sont déséquilibrées (jeux de données très faussés).</span><span class="sxs-lookup"><span data-stu-id="3d6f7-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="3d6f7-126">**Plus la précision est proche de 1,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="3d6f7-127">Des scores élevés proches de 1,00 montrent que le classifieur retourne des résultats précis (précision élevée) ainsi que la majorité de tous les résultats positifs (rappel élevé).</span><span class="sxs-lookup"><span data-stu-id="3d6f7-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="3d6f7-128">**Score F1**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-128">**F1-score**</span></span> | <span data-ttu-id="3d6f7-129">[Score F1](https://en.wikipedia.org/wiki/F1_score) également appelé *balanced F-score or F-measure*.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="3d6f7-130">Il s’agit de la moyenne harmonique de la précision et du rappel.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="3d6f7-131">Le score F1 est utile quand vous souhaitez rechercher un équilibre entre la précision et le rappel.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="3d6f7-132">**Plus la précision est proche de 1,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="3d6f7-133">Un score F1 atteint sa meilleure valeur à 1,00 et la pire à 0,00.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="3d6f7-134">Il vous indique le degré de précision de votre classifieur.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="3d6f7-135">Pour plus d’informations sur les métriques de classification binaire, consultez les articles suivants :</span><span class="sxs-lookup"><span data-stu-id="3d6f7-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="3d6f7-136">Précision, précision, rappel ou F1 ?</span><span class="sxs-lookup"><span data-stu-id="3d6f7-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="3d6f7-137">Classe BinaryClassificationMetrics</span><span class="sxs-lookup"><span data-stu-id="3d6f7-137">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="3d6f7-138">The Relationship Between Precision-Recall and ROC Curves</span><span class="sxs-lookup"><span data-stu-id="3d6f7-138">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="3d6f7-139">Métriques d’évaluation pour la classification multiclasse</span><span class="sxs-lookup"><span data-stu-id="3d6f7-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="3d6f7-140">Mesures</span><span class="sxs-lookup"><span data-stu-id="3d6f7-140">Metrics</span></span>   |      <span data-ttu-id="3d6f7-141">Description</span><span class="sxs-lookup"><span data-stu-id="3d6f7-141">Description</span></span>      |  <span data-ttu-id="3d6f7-142">Recherche</span><span class="sxs-lookup"><span data-stu-id="3d6f7-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="3d6f7-143">**Micro-précision**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="3d6f7-144">La [précision micro-moyenne](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) agrège les contributions de toutes les classes pour calculer la métrique moyenne.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="3d6f7-145">Il s’agit de la fraction d’instances correctement prédites.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="3d6f7-146">La micro-moyenne ne tient pas compte de l’appartenance aux classes.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="3d6f7-147">Fondamentalement, chaque paire exemple-classe contribue de manière égale à la métrique de précision.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="3d6f7-148">**Plus la précision est proche de 1,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="3d6f7-149">Dans une tâche de classification multiclasse, la micro-précision est préférable à la macro-précision si vous suspectez un déséquilibre de classes éventuel (</span><span class="sxs-lookup"><span data-stu-id="3d6f7-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="3d6f7-150">vous avez peut-être beaucoup plus d’exemples d’une classe que d’autres classes).</span><span class="sxs-lookup"><span data-stu-id="3d6f7-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="3d6f7-151">**Macro-précision**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="3d6f7-152">La [précision macro-moyenne](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) est la précision moyenne au niveau de la classe.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="3d6f7-153">La précision pour chaque classe est calculée et la macro-précision est la moyenne de ces précisions.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="3d6f7-154">Fondamentalement, chaque classe contribue de manière égale à la métrique de précision.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="3d6f7-155">Les classes minoritaires sont aussi importantes que les classes plus grandes.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="3d6f7-156">La métrique de macro-moyenne donne la même pondération à chaque classe, quel que soit le nombre d’instances de cette classe contenues dans le jeu de données.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="3d6f7-157">**Plus la précision est proche de 1,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="3d6f7-158">La métrique est calculée de manière indépendante pour chaque classe, puis la moyenne est calculée (toutes les classes étant ainsi traitées de façon égale)</span><span class="sxs-lookup"><span data-stu-id="3d6f7-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="3d6f7-159">**Perte de journal**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-159">**Log-loss**</span></span>| <span data-ttu-id="3d6f7-160">La perte logarithmique mesure les performances d’un modèle de classification où l’entrée de prédiction est une valeur de probabilité comprise entre 0,00 et 1,00.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-160">Logarithmic loss measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="3d6f7-161">La perte logarithmique augmente à mesure que la probabilité prédite diffère de l’étiquette réelle.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="3d6f7-162">**Plus la précision est proche de 0,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="3d6f7-163">Un modèle parfait aurait une perte logarithmique de 0,00.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="3d6f7-164">L’objectif de nos modèles Machine Learning consiste à réduire cette valeur.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="3d6f7-165">**Réduction de la perte logarithmique**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="3d6f7-166">La [réduction de la perte logarithmique](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) peut être interprétée comme exprimant l’avantage du classifieur par rapport à une prédiction aléatoire.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="3d6f7-167">**Elle est comprise entre -inf et 1,00, où 1,00 correspond à des prédictions parfaites et 0,00 à des prédictions moyennes**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="3d6f7-168">Par exemple, si la valeur est égale à 0,20, elle peut être interprétée comme « la probabilité d’une prédiction correcte est 20 % meilleure qu’une estimation aléatoire ».</span><span class="sxs-lookup"><span data-stu-id="3d6f7-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="3d6f7-169">La micro-précision est généralement mieux alignée sur les besoins métier de prédictions de ML.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="3d6f7-170">Si vous souhaitez sélectionner une seule métrique pour choisir la qualité d’une tâche de classification multiclasse, ce doit généralement être la micro-précision.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="3d6f7-171">Prenons l’exemple d’une tâche de classification de ticket de support (mappage des tickets entrants aux équipes de support technique) :</span><span class="sxs-lookup"><span data-stu-id="3d6f7-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="3d6f7-172">Micro-précision : avec quelle fréquence un ticket entrant est-il orienté vers l’équipe appropriée ?</span><span class="sxs-lookup"><span data-stu-id="3d6f7-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="3d6f7-173">Macro-précision : pour une équipe moyenne, avec quelle fréquence un ticket entrant est-il correct pour l’équipe concernée ?</span><span class="sxs-lookup"><span data-stu-id="3d6f7-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="3d6f7-174">La précision des macros est à l’échelle de petites équipes dans cet exemple ; une petite équipe qui obtient uniquement 10 tickets par an compte autant qu’une équipe de grande taille, avec un maximum de 10 000 tickets par an.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="3d6f7-175">Dans ce cas, la micro-précision présente une meilleure corrélation avec le besoin métier exprimé par « combien de temps et d’argent l’entreprise peut-elle économiser en automatisant mon processus de routage des tickets ».</span><span class="sxs-lookup"><span data-stu-id="3d6f7-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="3d6f7-176">Pour plus d’informations sur les métriques de classification multiclasse, consultez les articles suivants :</span><span class="sxs-lookup"><span data-stu-id="3d6f7-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="3d6f7-177">Micro-et macro-moyenne de précision, rappel et F-score</span><span class="sxs-lookup"><span data-stu-id="3d6f7-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="3d6f7-178">Multiclass Classification with Imbalanced Dataset</span><span class="sxs-lookup"><span data-stu-id="3d6f7-178">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="3d6f7-179">Mesures d’évaluation pour la régression et la recommandation</span><span class="sxs-lookup"><span data-stu-id="3d6f7-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="3d6f7-180">Les tâches de régression et de recommandation prédisent un nombre.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="3d6f7-181">Dans le cas de la régression, le nombre peut être toute propriété de sortie influencée par les propriétés d’entrée.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="3d6f7-182">Pour des recommandations, le nombre est généralement une valeur d’évaluation (entre 1 et 5, par exemple), ou une recommandation oui/non (représentée par 1 et 0 respectivement).</span><span class="sxs-lookup"><span data-stu-id="3d6f7-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="3d6f7-183">Métrique</span><span class="sxs-lookup"><span data-stu-id="3d6f7-183">Metric</span></span>   |      <span data-ttu-id="3d6f7-184">Description</span><span class="sxs-lookup"><span data-stu-id="3d6f7-184">Description</span></span>      |  <span data-ttu-id="3d6f7-185">Recherche</span><span class="sxs-lookup"><span data-stu-id="3d6f7-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="3d6f7-186">**R carré**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-186">**R-Squared**</span></span> |  <span data-ttu-id="3d6f7-187">Le *coefficient de détermination*, ou [R carré (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), représente la puissance prédictive du modèle sous la forme d’une valeur comprise entre -inf et 1,00.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="3d6f7-188">1,00 signifie un ajustement parfait ; l’ajustement peut être arbitrairement médiocre, les scores pouvant alors être négatifs.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="3d6f7-189">Un score de 0,00 signifie que le modèle devine la valeur attendue pour l’étiquette.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="3d6f7-190">R2 mesure la proximité des valeurs de données de test réelles des valeurs prédites.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="3d6f7-191">**Plus la précision est proche de 1,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="3d6f7-192">Cependant, de faibles valeurs de coefficient de détermination (par exemple 0,50) peuvent parfois être tout à fait normales ou suffisantes pour votre scénario, alors que des valeurs élevées ne conviennent pas toujours et peuvent être suspectes.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="3d6f7-193">**Perte absolue**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-193">**Absolute-loss**</span></span> |  <span data-ttu-id="3d6f7-194">La [perte absolue](https://en.wikipedia.org/wiki/Mean_absolute_error) ou *erreur d’absolue moyenne (MAE)* mesure la proximité des prédictions des résultats réels.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="3d6f7-195">Il s’agit de la moyenne de toutes les erreurs du modèle, où l’erreur de modèle est la distance absolue entre la valeur d’étiquette prédite et la valeur d’étiquette correcte.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="3d6f7-196">Cette erreur de prédiction est calculée pour chaque enregistrement du jeu de données de test.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="3d6f7-197">Enfin, la valeur moyenne est calculée pour toutes les erreurs d’absolue enregistrées.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="3d6f7-198">**Plus la précision est proche de 0,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="3d6f7-199">L’erreur absolue moyenne utilise la même échelle que les données mesurées (n’est pas normalisée pour une plage spécifique).</span><span class="sxs-lookup"><span data-stu-id="3d6f7-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="3d6f7-200">Vous ne pouvez utiliser l’erreur absolue, l’erreur quadratique moyenne et la racine de l’erreur quadratique moyenne que pour comparer des modèles pour le même jeu de données ou pour un jeu de données présentant une distribution similaire des valeurs d’étiquette.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="3d6f7-201">**Perte au carré**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-201">**Squared-loss**</span></span> |  <span data-ttu-id="3d6f7-202">Une [perte au carré ou une](https://en.wikipedia.org/wiki/Mean_squared_error) *erreur quadratique moyenne (MSE)*, également appelée *Ecart carré moyen (MSD)*, vous indique comment fermer une droite de régression à un ensemble de valeurs de données de test en utilisant les distances entre les points et la droite de régression (ces distances sont les erreurs E) et les met en forme.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="3d6f7-203">L’élévation au carré attribue une pondération supérieure aux différences plus grandes.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="3d6f7-204">Elle est toujours non négative, et **plus les valeurs sont proches de 0,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="3d6f7-205">En fonction de vos données, il peut s’avérer impossible d’obtenir une valeur très petite pour l’erreur quadratique moyenne.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="3d6f7-206">**Racine de l’erreur quadratique**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-206">**RMS-loss**</span></span> |  <span data-ttu-id="3d6f7-207">La [perte RMS](https://en.wikipedia.org/wiki/Root-mean-square_deviation) ou l' *erreur quadratique moyenne (RMSE)* (également appelée *Ecart carré moyen racine, RMSD*), mesure la différence entre les valeurs prédites par un modèle et les valeurs observées dans l’environnement modélisé.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="3d6f7-208">La racine de l’erreur quadratique moyenne est la racine carrée de l’erreur quadratique moyenne et a les mêmes unités que l’étiquette, à l’image de l’erreur absolue, bien que les différences plus grandes se voient attribuer une pondération supérieure.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="3d6f7-209">La racine de l’erreur quadratique moyenne est couramment utilisée dans les domaines de la climatologie, des prévisions et de l’analyse de régression pour vérifier des résultats expérimentaux.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="3d6f7-210">Elle est toujours non négative, et **plus les valeurs sont proches de 0,00, meilleure est la qualité**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="3d6f7-211">La racine de l’erreur quadratique moyenne est une mesure de précision, qui compare les erreurs de prévision de différents modèles pour un jeu de données particulier et non entre plusieurs jeux de données, étant dépendante de l’échelle.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="3d6f7-212">Pour plus d’informations sur les métriques de régression, consultez les articles suivants :</span><span class="sxs-lookup"><span data-stu-id="3d6f7-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="3d6f7-213">Analyse de régression : comment interpréter la R-squareie et évaluer l’adéquation ?</span><span class="sxs-lookup"><span data-stu-id="3d6f7-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="3d6f7-214">How To Interpret R-squared in Regression Analysis</span><span class="sxs-lookup"><span data-stu-id="3d6f7-214">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="3d6f7-215">R-Squared Definition</span><span class="sxs-lookup"><span data-stu-id="3d6f7-215">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="3d6f7-216">Mean Squared Error Definition</span><span class="sxs-lookup"><span data-stu-id="3d6f7-216">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="3d6f7-217">What are Mean Squared Error and Root Mean Squared Error?</span><span class="sxs-lookup"><span data-stu-id="3d6f7-217">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="3d6f7-218">Métriques d’évaluation pour le clustering</span><span class="sxs-lookup"><span data-stu-id="3d6f7-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="3d6f7-219">Métrique</span><span class="sxs-lookup"><span data-stu-id="3d6f7-219">Metric</span></span>   |      <span data-ttu-id="3d6f7-220">Description</span><span class="sxs-lookup"><span data-stu-id="3d6f7-220">Description</span></span>      |  <span data-ttu-id="3d6f7-221">Recherche</span><span class="sxs-lookup"><span data-stu-id="3d6f7-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="3d6f7-222">**Distance moyenne**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-222">**Average Distance**</span></span>|<span data-ttu-id="3d6f7-223">Moyenne de la distance entre les points de données et le centre de leur cluster affecté.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="3d6f7-224">La distance moyenne est une mesure de la proximité des points de données aux centroïdes de cluster.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="3d6f7-225">Il s’agit d’une mesure de la « rigueur » du cluster.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="3d6f7-226">Les valeurs proches de **0** sont préférables.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-226">Values closer to **0** are better.</span></span> <span data-ttu-id="3d6f7-227">Plus la distance moyenne est proche de zéro, plus les données sont en cluster.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="3d6f7-228">Notez cependant que cette mesure diminue si le nombre de clusters augmente, et dans le cas extrême (où chaque point de données distinct est son propre cluster) elle est égale à zéro.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="3d6f7-229">**Index Davies Bouldin**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="3d6f7-230">Rapport moyen entre les distances au sein du cluster et les distances entre les clusters.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="3d6f7-231">Plus le cluster est étroit et plus les clusters sont éloignés, plus cette valeur est faible.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="3d6f7-232">Les valeurs proches de **0** sont préférables.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-232">Values closer to **0** are better.</span></span> <span data-ttu-id="3d6f7-233">Les clusters plus éloignés et moins dispersés ont un meilleur score.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="3d6f7-234">**Informations mutuelles normalisées**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="3d6f7-235">Peut être utilisé lorsque les données d’apprentissage utilisées pour l’apprentissage du modèle de clustering sont également fournies avec des étiquettes de vérité à la terre (autrement dit, le clustering supervisé).</span><span class="sxs-lookup"><span data-stu-id="3d6f7-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="3d6f7-236">La mesure d’informations mutuelle normalisée mesure si des points de données similaires sont affectés au même cluster et que des points de données disparates sont affectés à des clusters différents.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="3d6f7-237">Les informations mutuelles normalisées sont une valeur comprise entre 0 et 1</span><span class="sxs-lookup"><span data-stu-id="3d6f7-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="3d6f7-238">Les valeurs proches de **1** sont meilleures</span><span class="sxs-lookup"><span data-stu-id="3d6f7-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="3d6f7-239">Métriques d’évaluation pour le classement</span><span class="sxs-lookup"><span data-stu-id="3d6f7-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="3d6f7-240">Métrique</span><span class="sxs-lookup"><span data-stu-id="3d6f7-240">Metric</span></span>   |      <span data-ttu-id="3d6f7-241">Description</span><span class="sxs-lookup"><span data-stu-id="3d6f7-241">Description</span></span>      |  <span data-ttu-id="3d6f7-242">Recherche</span><span class="sxs-lookup"><span data-stu-id="3d6f7-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="3d6f7-243">**Gains cumulés avec remise**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="3d6f7-244">Le gain cumulatif avec remise (DCG) est une mesure de la qualité du classement.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="3d6f7-245">Il est dérivé de deux hypothèses.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-245">It is derived from two assumptions.</span></span> <span data-ttu-id="3d6f7-246">Un : les éléments les plus pertinents sont plus utiles lorsqu’ils apparaissent plus haut dans l’ordre de classement.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="3d6f7-247">Deux : l’utilité effectue le suivi de la pertinence, plus la pertinence est élevée, plus un élément est utile.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="3d6f7-248">Le gain cumulatif à prix réduit est calculé pour une position particulière dans l’ordre de classement.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="3d6f7-249">Il additionne la notation de la pertinence divisée par le logarithme de l’index de classement jusqu’à la position d’intérêt.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="3d6f7-250">Elle est calculée à l’aide de $ \ sum_ {i = 0} ^ {p} \frac {rel_i} {\ log_ {e} {i + 1}} $ les notations de pertinence sont fournies à un algorithme d’apprentissage de classement en tant qu’étiquettes de vérité au sol.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="3d6f7-251">Une valeur DCG est fournie pour chaque position dans la table de classement, par conséquent les **gains**cumulatifs avec remise de nom.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="3d6f7-252">**Les valeurs élevées sont meilleures**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-252">**Higher values are better**</span></span>|
|<span data-ttu-id="3d6f7-253">**Gains cumulatifs à prix réduit normalisés**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="3d6f7-254">La normalisation de DCG permet la comparaison de la métrique pour les listes de classement de longueurs différentes</span><span class="sxs-lookup"><span data-stu-id="3d6f7-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="3d6f7-255">**Les valeurs proches de 1 sont meilleures**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="3d6f7-256">Mesures d’évaluation pour la détection des anomalies</span><span class="sxs-lookup"><span data-stu-id="3d6f7-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="3d6f7-257">Métrique</span><span class="sxs-lookup"><span data-stu-id="3d6f7-257">Metric</span></span>   |      <span data-ttu-id="3d6f7-258">Description</span><span class="sxs-lookup"><span data-stu-id="3d6f7-258">Description</span></span>      |  <span data-ttu-id="3d6f7-259">Recherche</span><span class="sxs-lookup"><span data-stu-id="3d6f7-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="3d6f7-260">**Zone sous courbe ROC**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="3d6f7-261">Zone sous la courbe opérateur du récepteur mesure la manière dont le modèle sépare les points de données anormaux et anormaux.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="3d6f7-262">**Les valeurs plus proches de 1 sont préférables**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="3d6f7-263">Seules les valeurs supérieures à 0,5 illustrent l’efficacité du modèle.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="3d6f7-264">Les valeurs de 0,5 ou ci-dessous indiquent que le modèle n’est pas mieux que d’allouer aléatoirement les entrées aux catégories anormales et usuelles</span><span class="sxs-lookup"><span data-stu-id="3d6f7-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="3d6f7-265">**Taux de détection sur le nombre de faux positifs**</span><span class="sxs-lookup"><span data-stu-id="3d6f7-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="3d6f7-266">Le taux de détection sur le nombre de faux positifs est le rapport entre le nombre d’anomalies correctement identifiées et le nombre total d’anomalies dans un jeu de test, indexées par chaque faux positif.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="3d6f7-267">Autrement dit, il existe une valeur pour taux de détection sur le nombre de faux positifs pour chaque élément de faux positif.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="3d6f7-268">**Les valeurs plus proches de 1 sont préférables**.</span><span class="sxs-lookup"><span data-stu-id="3d6f7-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="3d6f7-269">S’il n’existe aucun faux positif, cette valeur est 1</span><span class="sxs-lookup"><span data-stu-id="3d6f7-269">If there are no false positives, then this value is 1</span></span>|
